<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>데이터 엔지니어링 on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/</link>
    <description>Recent content in 데이터 엔지니어링 on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Sep 2021 18:10:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>파이썬을 활용한 JSON 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</link>
      <pubDate>Wed, 08 Sep 2021 18:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</guid>
      <description>개요  JSON은 (JavaScript Object Notataion)의 약자이며, 주로 API 호출 시에 사용한다. JSON 데이터를 개별적인 파일 형태로 저장하기도 한다. json 라이브러리를 활용하여 입출력을 진행하고, pandas 라이브러리를 통해서도 직접 불러오도록 한다.  JSON 파일 쓰기 전체 코드  파일은 wirtejson.py 형태로 저장한다.  from faker import Faker import json output=open(&amp;#39;data.json&amp;#39;,&amp;#39;w&amp;#39;) fake=Faker() all_df={} all_df[&amp;#39;records&amp;#39;]=[] for x in range(1000): data={&amp;#34;name&amp;#34;:fake.name(), &amp;#34;age&amp;#34;:fake.random_int(min=18, max=80, step=1), &amp;#34;street&amp;#34;:fake.street_address(), &amp;#34;city&amp;#34;:fake.city(), &amp;#34;state&amp;#34;:fake.state(), &amp;#34;zip&amp;#34;:fake.zipcode(), &amp;#34;lng&amp;#34;:float(fake.longitude()), &amp;#34;lat&amp;#34;:float(fake.latitude())} all_df[&amp;#39;records&amp;#39;].append(data)	json.dump(all_df,output)  faker 라이브러리 설명은 파이썬을 활용한 파일 입출력 예제 with faker 에서 확인한다.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 CSV 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</link>
      <pubDate>Wed, 08 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</guid>
      <description>사전 작업  우선 임시 데이터를 기록할 라이브러리인 faker 를 설치한다. 흔히 쓰이는 필드들을 함수 하나로 쉽게 만들 수 있도록 지원한다.  (venv) $ pip3 install faker 데이터 생성하기 전체 코드  필자는 [writecsv.py](http://writecsv.py) 형태로 저장하였다. 먼저 한줄 씩 설명하면 다음과 같다.  from faker import Faker import csv output=open(&amp;#39;mydata.csv&amp;#39;, mode = &amp;#39;w&amp;#39;) fake=Faker() header=[&amp;#39;name&amp;#39;,&amp;#39;age&amp;#39;,&amp;#39;street&amp;#39;,&amp;#39;city&amp;#39;,&amp;#39;state&amp;#39;,&amp;#39;zip&amp;#39;,&amp;#39;lng&amp;#39;,&amp;#39;lat&amp;#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.writerow([fake.name(),fake.random_int(min=18, max=80, step=1), fake.street_address(), fake.city(),fake.state(),fake.zipcode(),fake.longitude(),fake.latitude()]) output.close()  from faker import Faker 는 라이브러리를 불러오는 것이다.</description>
    </item>
    
    <item>
      <title>Kibana Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</link>
      <pubDate>Tue, 07 Sep 2021 13:13:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</guid>
      <description>개요  Elastic Search는 GUI를 제공하지 않고 API만 제공한다. 따라서, 시각화 도구인 키바나를 GUI로 사용하도록 하는 것이 특징이다.  Elastic Search 설치는 Elastic Search Engine Installation에서 확인한다.   즉, 다시 말하면 Elastic Search 는 API 데이터만 제공할 뿐이고, 이를 가시적으로 보여주기 위해서는 Kibana를 설치해야 한다는 뜻이다.  설치  기본적인 설치 메뉴얼은 Install Kibana에서 확인이 가능하다. 본 책에서는 MacOS 설치 과정으로 진행을 하였다.  Install Kibana from archive on Linux or macOS 코드는 다음과 같다.</description>
    </item>
    
    <item>
      <title>Elastic Search Engine Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</link>
      <pubDate>Tue, 07 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</guid>
      <description>개요  검색 엔진을 말한다. Mac에서 설치하는 과정을 진행한다. 가상 환경은 virtualenv 를 통해서 진행한다.  참조: https://lee-mandu.tistory.com/517?category=838684   그 후에 가상 환경에 접속한다.  설치  각 OS별 설치 과정은 해당 URL에서 참조할 수 있다.  URL: https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html MacOS: https://www.elastic.co/guide/en/elasticsearch/reference/current/targz.html   설치는 다음 코드를 순차적으로 실행하면 끝이 난다.  (venv) $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.1-darwin-x86_64.tar.gz (venv) $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.1-darwin-x86_64.tar.gz.sha512 (venv) $ shasum -a 512 -c elasticsearch-7.14.1-darwin-x86_64.tar.gz.sha512 (venv) $ tar -xzf elasticsearch-7.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>개요  NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다. 가상 환경은 virtualenv 를 통해서 진행한다.  참조: https://lee-mandu.tistory.com/517?category=838684   그 후에 가상 환경에 접속한다.  $ source venv/bin/activate (venv) $ Step 01. 환경변수 설정  우선 pip 으로 설치 하기에 앞서서 환경 변수를 임시로 설정한다. 해당 환경 변수가 설정된 곳으로 airflow 설치 관련 폴더 및 파일들이 다운로드 될 것이다.</description>
    </item>
    
    <item>
      <title>Apache NiFi Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</link>
      <pubDate>Mon, 06 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</guid>
      <description>개요  데이터 엔지니어링에 필요한 기본적인 인프라를 설치 진행하는 튜토리얼을 만들었다. 기본적으로 교재에 충실하지만, 약 1년전에 쓰인 책이라, 최신 버전으로 업그레이드 하였다.  Apache NiFi 설치과정  먼저 웹사이트에 방문하여 필요한 파일을 다운로드 받는다.  URL: https://nifi.apache.org/download.html     wget을 이용해서 NiFi를 현재 디렉터리에 내려받는다.  $ wget https://downloads.apache.org/nifi/1.14.0/nifi-1.14.0-bin.tar.gz --2021-09-06 13:10:55-- https://downloads.apache.org/nifi/1.14.0/nifi-1.14.0-bin.tar.gz Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 135.181.209.10, 88.99.95.219 Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1417663663 (1.</description>
    </item>
    
  </channel>
</rss>
