<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airflow on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/tags/airflow/</link>
    <description>Recent content in Airflow on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Sep 2021 11:10:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/tags/airflow/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Airflow를 활용한 CSV에서 JSON으로 변환하기</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</link>
      <pubDate>Thu, 09 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</guid>
      <description>개요  Apache Airflow에서 가장 중요한 개념은 DAG(Directed Acyclic Graph)이다. DAG를 만들 시, Bash 스크립트 및 연산자(Operator)로 작업을 정의할 수 있다. 이 때, 파이썬 함수로 조직화 한다. Airflow 설치방법을 모른다면 다음 페이지에서 확인한다.  Apache Airflow Installation    Step 01. Building a CSV to a JSON data pipeline  우선 전체적인 코드를 확인한다. 필자의 airflow 버전은 2.13이다. 이 때, 몇몇 코드는 아래와 같이 발견될 수도 있다.  from airflow.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>개요  NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다. 가상 환경은 virtualenv 를 통해서 진행한다.  참조: https://lee-mandu.tistory.com/517?category=838684   그 후에 가상 환경에 접속한다.  $ source venv/bin/activate (venv) $ Step 01. 환경변수 설정  우선 pip 으로 설치 하기에 앞서서 환경 변수를 임시로 설정한다. 해당 환경 변수가 설정된 곳으로 airflow 설치 관련 폴더 및 파일들이 다운로드 될 것이다.</description>
    </item>
    
    <item>
      <title>AirFlow ch01. 개요</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</link>
      <pubDate>Fri, 09 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</guid>
      <description>공지  Airflow 2.0 원서 나온 것을 공부용으로 활용합니다.  Airflow Project  이 책에 나온 내용을 Chapter별로 요약하여 정리하려고 한다. 원서 구매 페이지는 아래와 같다. 구매 페이지: Data Pipelines with Apache Airflow  Chapter 1. Apache Airflow Introduction Figure 1.1 Overview of the weather dashboard use case, in which weather data is fetched from an external API and fed into a dynamic dashboard
  기상청 API를 활용하여 대시보드를 만든다고 가정한다.</description>
    </item>
    
    <item>
      <title>AirFlow 설치 및 실행 with M1</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</link>
      <pubDate>Thu, 08 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</guid>
      <description>미니 프로젝트 개요  목적: Airflow와 빅쿼리를 활용하여 ETL 및 대시보드를 만들어보는 과정을 설계 환경: MacOS M1  Part I. Docker and Airflow   Docker와 Airflow를 설치 및 실행한다.
  필자는 가상환경을 선정하고, 그 위에 도커를 추가로 설치하였다.
 목적: 로컬과 환경 격리    PyCharm에서 먼저 환경 추가를 위해 아래 그림처럼 단계적으로 버튼을 클릭한다.
 [PyCharm] - [Preferences] - [Project] - [Python Interpreter] - [Add] - [Virtualenv]     이제 해당 가상 환경에 접속을 한다.</description>
    </item>
    
  </channel>
</rss>
