<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/categories/data-engineering/</link>
    <description>Recent content in Data Engineering on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Apr 2022 21:10:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/categories/data-engineering/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Airflow 데이터 파이프라인 구축 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</link>
      <pubDate>Thu, 14 Apr 2022 21:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</guid>
      <description>개요 이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다. Step 01. Dags 폴더 생성 프로젝트 Root 하단에 Dags 폴더를 만든다. dags 폴더를 확인한다. $ ls airflow.cfg airflow.db dags logs venv webserver_config.py Step 02. 가상의 데이터 생성 이번 테스트에서 사용할 라이브러리가 없다면 우선 설치한다. $ pip3 install faker pandas faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data/step01_writecsv.py) from faker import Faker import csv output=open(&amp;#39;data.csv&amp;#39;,&amp;#39;w&amp;#39;) fake=Faker() header=[&amp;#39;name&amp;#39;,&amp;#39;age&amp;#39;,&amp;#39;street&amp;#39;,&amp;#39;city&amp;#39;,&amp;#39;state&amp;#39;,&amp;#39;zip&amp;#39;,&amp;#39;lng&amp;#39;,&amp;#39;lat&amp;#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 Data Cleansing 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</link>
      <pubDate>Mon, 20 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Pandas와 Airflow를 활용하여 데이터를 정제하는 코드를 구성한다. 우선 데이터는 아래에서 CSV 파일을 다운로드 받고, Dags 파일 하단에 위치시킨다. URL: https://github.com/PaulCrickard/escooter/blob/master/scooter.csv Raw 데이터 확인 간단하게 Raw 데이터를 확인해보도록 한다. import pandas as pd df = pd.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 PostgreSQL에서 Elasticsearch로 데이터 마이그레이션 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</link>
      <pubDate>Sat, 18 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Airflow를 활용하여 PostgreSQL에 저장된 데이터를 디스크로 다운로드 받고, 그리고 그 파일을 다시 읽어서 Elasticsearch에 저장하도록 한다. 전체적인 흐름은 getData from PostgreSQL &amp;gt;&amp;gt; insertData to Elasticsearch 로 저장할 수 있다. 전체 코드 실행 우선 전체 코드를 실행하도록 한다.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 엘라스틱서치에서 데이터 추출</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_python_extract/</link>
      <pubDate>Fri, 17 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_python_extract/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 데이터를 질의하는 방법과 데이터를 삽입하는 방법은 동일하다. 다만, 이 때에는 search 메서드를 사용하다. 또한, doc 문서도 조금 다르다. 기본적으로 SQL 과 문법이 다르기 때문에 공식문서를 확인한다. 실행 본 테스트를 실행하기에 앞서서, Elasticsearch 과 Kibana 를 먼저 구동시키고, 데이터가 미리 삽입 되어 있으면 좋다.</description>
    </item>
    
    <item>
      <title>파이썬과 엘라스틱서치 DB 연동</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_with_python_dbinsert/</link>
      <pubDate>Wed, 15 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_with_python_dbinsert/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 NoSQL 데이터베이스 시스템의 하나인 Elasticsearch 를 다루는 방법을 설명한다. NoSQL 은 데이터를 행들과 열들로 저장하지 않는 데이터베이스를 말한다. 대개 JSON문서 형태로 저장하고, SQL이 아닌 절의 언어를 주로 사용한다. 설치 먼저 설치를 진행한다. (venv) $ pip3 install elasticsearch Collecting elasticsearch Downloading elasticsearch-7.</description>
    </item>
    
    <item>
      <title>파이썬과 PostgreSQL DB 연동 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/python_postgresql/</link>
      <pubDate>Fri, 10 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/python_postgresql/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 MacOS에서의 기본 설치 과정은 생략하도록 한다. 새로운 DB를 생성하도록 한다. 먼저 환경변수를 설정한다. 해당 경로를 가져오는 방법은 Postgre SQL Installation on MacOS M1에서 확인한다. (venv) $ export PATH=/opt/homebrew/bin:$PATH:/Applications/Postgres.app/Contents/Versions/13/bin 먼저 기본 데이터베이스에 연결한다. (venv) $ psql postgres psql (13.</description>
    </item>
    
    <item>
      <title>Apache Airflow를 활용한 CSV에서 JSON으로 변환하기</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</link>
      <pubDate>Thu, 09 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Apache Airflow에서 가장 중요한 개념은 DAG(Directed Acyclic Graph)이다. DAG를 만들 시, Bash 스크립트 및 연산자(Operator)로 작업을 정의할 수 있다. 이 때, 파이썬 함수로 조직화 한다. Airflow 설치방법을 모른다면 다음 페이지에서 확인한다. Apache Airflow Installation Step 01.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 JSON 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</link>
      <pubDate>Wed, 08 Sep 2021 18:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 JSON은 (JavaScript Object Notataion)의 약자이며, 주로 API 호출 시에 사용한다. JSON 데이터를 개별적인 파일 형태로 저장하기도 한다. json 라이브러리를 활용하여 입출력을 진행하고, pandas 라이브러리를 통해서도 직접 불러오도록 한다. JSON 파일 쓰기 전체 코드 파일은 wirtejson.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 CSV 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</link>
      <pubDate>Wed, 08 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 사전 작업 우선 임시 데이터를 기록할 라이브러리인 faker 를 설치한다. 흔히 쓰이는 필드들을 함수 하나로 쉽게 만들 수 있도록 지원한다. (venv) $ pip3 install faker 데이터 생성하기 전체 코드 필자는 [writecsv.py](http://writecsv.py) 형태로 저장하였다. 먼저 한줄 씩 설명하면 다음과 같다.</description>
    </item>
    
    <item>
      <title>Kibana Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</link>
      <pubDate>Tue, 07 Sep 2021 13:13:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Elastic Search는 GUI를 제공하지 않고 API만 제공한다. 따라서, 시각화 도구인 키바나를 GUI로 사용하도록 하는 것이 특징이다. Elastic Search 설치는 Elastic Search Engine Installation에서 확인한다. 즉, 다시 말하면 Elastic Search 는 API 데이터만 제공할 뿐이고, 이를 가시적으로 보여주기 위해서는 Kibana를 설치해야 한다는 뜻이다.</description>
    </item>
    
    <item>
      <title>Elastic Search Engine Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</link>
      <pubDate>Tue, 07 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 검색 엔진을 말한다. Mac에서 설치하는 과정을 진행한다. 가상 환경은 virtualenv 를 통해서 진행한다. 참조: https://lee-mandu.tistory.com/517?category=838684 그 후에 가상 환경에 접속한다. 설치 각 OS별 설치 과정은 해당 URL에서 참조할 수 있다. URL: https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html MacOS: https://www.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다. 가상 환경은 virtualenv 를 통해서 진행한다.</description>
    </item>
    
    <item>
      <title>Apache NiFi Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</link>
      <pubDate>Mon, 06 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 데이터 엔지니어링에 필요한 기본적인 인프라를 설치 진행하는 튜토리얼을 만들었다. 기본적으로 교재에 충실하지만, 약 1년전에 쓰인 책이라, 최신 버전으로 업그레이드 하였다. Apache NiFi 설치과정 먼저 웹사이트에 방문하여 필요한 파일을 다운로드 받는다. URL: https://nifi.apache.org/download.html wget을 이용해서 NiFi를 현재 디렉터리에 내려받는다.</description>
    </item>
    
  </channel>
</rss>
